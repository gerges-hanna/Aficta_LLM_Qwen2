{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.999205298013245,
  "eval_steps": 500,
  "global_step": 1886,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010596026490066225,
      "grad_norm": 0.3652186095714569,
      "learning_rate": 0.0001980911983032874,
      "loss": 0.3805,
      "step": 10
    },
    {
      "epoch": 0.02119205298013245,
      "grad_norm": 0.5523431301116943,
      "learning_rate": 0.00019597030752916225,
      "loss": 0.4265,
      "step": 20
    },
    {
      "epoch": 0.031788079470198675,
      "grad_norm": 0.3952833116054535,
      "learning_rate": 0.00019384941675503712,
      "loss": 0.3839,
      "step": 30
    },
    {
      "epoch": 0.0423841059602649,
      "grad_norm": 0.3053360879421234,
      "learning_rate": 0.000191728525980912,
      "loss": 0.3808,
      "step": 40
    },
    {
      "epoch": 0.052980132450331126,
      "grad_norm": 0.47460371255874634,
      "learning_rate": 0.00018960763520678686,
      "loss": 0.3744,
      "step": 50
    },
    {
      "epoch": 0.06357615894039735,
      "grad_norm": 0.4034351706504822,
      "learning_rate": 0.00018748674443266173,
      "loss": 0.4098,
      "step": 60
    },
    {
      "epoch": 0.07417218543046358,
      "grad_norm": 0.427176296710968,
      "learning_rate": 0.0001853658536585366,
      "loss": 0.385,
      "step": 70
    },
    {
      "epoch": 0.0847682119205298,
      "grad_norm": 0.38056471943855286,
      "learning_rate": 0.00018324496288441147,
      "loss": 0.3855,
      "step": 80
    },
    {
      "epoch": 0.09536423841059603,
      "grad_norm": 0.2585345506668091,
      "learning_rate": 0.0001811240721102863,
      "loss": 0.3588,
      "step": 90
    },
    {
      "epoch": 0.10596026490066225,
      "grad_norm": 0.49608489871025085,
      "learning_rate": 0.00017900318133616118,
      "loss": 0.3874,
      "step": 100
    },
    {
      "epoch": 0.11655629139072848,
      "grad_norm": 0.38115832209587097,
      "learning_rate": 0.00017688229056203608,
      "loss": 0.3646,
      "step": 110
    },
    {
      "epoch": 0.1271523178807947,
      "grad_norm": 0.35526242852211,
      "learning_rate": 0.00017476139978791092,
      "loss": 0.4024,
      "step": 120
    },
    {
      "epoch": 0.13774834437086092,
      "grad_norm": 0.42625778913497925,
      "learning_rate": 0.0001726405090137858,
      "loss": 0.365,
      "step": 130
    },
    {
      "epoch": 0.14834437086092717,
      "grad_norm": 0.3582116365432739,
      "learning_rate": 0.00017051961823966066,
      "loss": 0.3715,
      "step": 140
    },
    {
      "epoch": 0.15894039735099338,
      "grad_norm": 0.4997309744358063,
      "learning_rate": 0.00016839872746553553,
      "loss": 0.3787,
      "step": 150
    },
    {
      "epoch": 0.1695364238410596,
      "grad_norm": 0.4481487274169922,
      "learning_rate": 0.0001662778366914104,
      "loss": 0.3511,
      "step": 160
    },
    {
      "epoch": 0.18013245033112582,
      "grad_norm": 0.3717636466026306,
      "learning_rate": 0.00016415694591728527,
      "loss": 0.3708,
      "step": 170
    },
    {
      "epoch": 0.19072847682119207,
      "grad_norm": 0.40182971954345703,
      "learning_rate": 0.00016203605514316014,
      "loss": 0.3988,
      "step": 180
    },
    {
      "epoch": 0.20132450331125828,
      "grad_norm": 0.4467674195766449,
      "learning_rate": 0.000159915164369035,
      "loss": 0.3707,
      "step": 190
    },
    {
      "epoch": 0.2119205298013245,
      "grad_norm": 0.5250430703163147,
      "learning_rate": 0.00015779427359490988,
      "loss": 0.3838,
      "step": 200
    },
    {
      "epoch": 0.22251655629139072,
      "grad_norm": 0.4450741112232208,
      "learning_rate": 0.00015567338282078473,
      "loss": 0.3409,
      "step": 210
    },
    {
      "epoch": 0.23311258278145697,
      "grad_norm": 0.3692467212677002,
      "learning_rate": 0.0001535524920466596,
      "loss": 0.3843,
      "step": 220
    },
    {
      "epoch": 0.24370860927152319,
      "grad_norm": 0.37054333090782166,
      "learning_rate": 0.00015143160127253447,
      "loss": 0.3632,
      "step": 230
    },
    {
      "epoch": 0.2543046357615894,
      "grad_norm": 0.3989076316356659,
      "learning_rate": 0.00014931071049840934,
      "loss": 0.3648,
      "step": 240
    },
    {
      "epoch": 0.26490066225165565,
      "grad_norm": 0.48739945888519287,
      "learning_rate": 0.0001471898197242842,
      "loss": 0.3507,
      "step": 250
    },
    {
      "epoch": 0.27549668874172184,
      "grad_norm": 0.4144405126571655,
      "learning_rate": 0.00014506892895015908,
      "loss": 0.3701,
      "step": 260
    },
    {
      "epoch": 0.2860927152317881,
      "grad_norm": 0.41041797399520874,
      "learning_rate": 0.00014294803817603395,
      "loss": 0.3822,
      "step": 270
    },
    {
      "epoch": 0.29668874172185433,
      "grad_norm": 0.33502107858657837,
      "learning_rate": 0.00014082714740190882,
      "loss": 0.3667,
      "step": 280
    },
    {
      "epoch": 0.3072847682119205,
      "grad_norm": 0.4352269470691681,
      "learning_rate": 0.00013870625662778366,
      "loss": 0.3474,
      "step": 290
    },
    {
      "epoch": 0.31788079470198677,
      "grad_norm": 0.43929728865623474,
      "learning_rate": 0.00013658536585365856,
      "loss": 0.3617,
      "step": 300
    },
    {
      "epoch": 0.32847682119205296,
      "grad_norm": 0.45373526215553284,
      "learning_rate": 0.0001344644750795334,
      "loss": 0.3594,
      "step": 310
    },
    {
      "epoch": 0.3390728476821192,
      "grad_norm": 0.42339465022087097,
      "learning_rate": 0.00013234358430540827,
      "loss": 0.3616,
      "step": 320
    },
    {
      "epoch": 0.34966887417218545,
      "grad_norm": 0.5322495102882385,
      "learning_rate": 0.00013022269353128314,
      "loss": 0.3602,
      "step": 330
    },
    {
      "epoch": 0.36026490066225164,
      "grad_norm": 0.41164085268974304,
      "learning_rate": 0.00012810180275715801,
      "loss": 0.3537,
      "step": 340
    },
    {
      "epoch": 0.3708609271523179,
      "grad_norm": 0.40948066115379333,
      "learning_rate": 0.00012598091198303288,
      "loss": 0.3598,
      "step": 350
    },
    {
      "epoch": 0.38145695364238413,
      "grad_norm": 0.4404812157154083,
      "learning_rate": 0.00012386002120890773,
      "loss": 0.3715,
      "step": 360
    },
    {
      "epoch": 0.3920529801324503,
      "grad_norm": 0.4388227164745331,
      "learning_rate": 0.00012173913043478263,
      "loss": 0.3633,
      "step": 370
    },
    {
      "epoch": 0.40264900662251657,
      "grad_norm": 0.43427300453186035,
      "learning_rate": 0.00011961823966065748,
      "loss": 0.358,
      "step": 380
    },
    {
      "epoch": 0.41324503311258276,
      "grad_norm": 0.46176961064338684,
      "learning_rate": 0.00011749734888653234,
      "loss": 0.377,
      "step": 390
    },
    {
      "epoch": 0.423841059602649,
      "grad_norm": 0.38346782326698303,
      "learning_rate": 0.00011537645811240722,
      "loss": 0.3362,
      "step": 400
    },
    {
      "epoch": 0.43443708609271525,
      "grad_norm": 0.40656349062919617,
      "learning_rate": 0.00011325556733828209,
      "loss": 0.3587,
      "step": 410
    },
    {
      "epoch": 0.44503311258278144,
      "grad_norm": 0.4437779188156128,
      "learning_rate": 0.00011113467656415695,
      "loss": 0.3761,
      "step": 420
    },
    {
      "epoch": 0.4556291390728477,
      "grad_norm": 0.3892826735973358,
      "learning_rate": 0.0001090137857900318,
      "loss": 0.3543,
      "step": 430
    },
    {
      "epoch": 0.46622516556291393,
      "grad_norm": 0.36478763818740845,
      "learning_rate": 0.00010689289501590669,
      "loss": 0.3663,
      "step": 440
    },
    {
      "epoch": 0.4768211920529801,
      "grad_norm": 0.35894420742988586,
      "learning_rate": 0.00010477200424178155,
      "loss": 0.366,
      "step": 450
    },
    {
      "epoch": 0.48741721854304637,
      "grad_norm": 0.4231663942337036,
      "learning_rate": 0.00010265111346765642,
      "loss": 0.3667,
      "step": 460
    },
    {
      "epoch": 0.49801324503311256,
      "grad_norm": 0.39059361815452576,
      "learning_rate": 0.0001005302226935313,
      "loss": 0.3733,
      "step": 470
    },
    {
      "epoch": 0.5086092715231788,
      "grad_norm": 0.3684982359409332,
      "learning_rate": 9.840933191940616e-05,
      "loss": 0.3864,
      "step": 480
    },
    {
      "epoch": 0.519205298013245,
      "grad_norm": 0.37994885444641113,
      "learning_rate": 9.628844114528103e-05,
      "loss": 0.3567,
      "step": 490
    },
    {
      "epoch": 0.5298013245033113,
      "grad_norm": 0.6198938488960266,
      "learning_rate": 9.416755037115588e-05,
      "loss": 0.365,
      "step": 500
    },
    {
      "epoch": 0.5403973509933775,
      "grad_norm": 0.47755616903305054,
      "learning_rate": 9.204665959703075e-05,
      "loss": 0.3506,
      "step": 510
    },
    {
      "epoch": 0.5509933774834437,
      "grad_norm": 0.4621831178665161,
      "learning_rate": 8.992576882290563e-05,
      "loss": 0.359,
      "step": 520
    },
    {
      "epoch": 0.56158940397351,
      "grad_norm": 0.46743690967559814,
      "learning_rate": 8.78048780487805e-05,
      "loss": 0.3489,
      "step": 530
    },
    {
      "epoch": 0.5721854304635762,
      "grad_norm": 0.3445144593715668,
      "learning_rate": 8.568398727465537e-05,
      "loss": 0.3476,
      "step": 540
    },
    {
      "epoch": 0.5827814569536424,
      "grad_norm": 0.44425278902053833,
      "learning_rate": 8.356309650053022e-05,
      "loss": 0.352,
      "step": 550
    },
    {
      "epoch": 0.5933774834437087,
      "grad_norm": 0.40156760811805725,
      "learning_rate": 8.144220572640509e-05,
      "loss": 0.3595,
      "step": 560
    },
    {
      "epoch": 0.6039735099337749,
      "grad_norm": 0.5007280707359314,
      "learning_rate": 7.932131495227996e-05,
      "loss": 0.3473,
      "step": 570
    },
    {
      "epoch": 0.614569536423841,
      "grad_norm": 0.44738078117370605,
      "learning_rate": 7.720042417815483e-05,
      "loss": 0.3559,
      "step": 580
    },
    {
      "epoch": 0.6251655629139072,
      "grad_norm": 0.355879545211792,
      "learning_rate": 7.50795334040297e-05,
      "loss": 0.3485,
      "step": 590
    },
    {
      "epoch": 0.6357615894039735,
      "grad_norm": 0.4550936818122864,
      "learning_rate": 7.295864262990456e-05,
      "loss": 0.3486,
      "step": 600
    },
    {
      "epoch": 0.6463576158940397,
      "grad_norm": 0.6194154620170593,
      "learning_rate": 7.083775185577943e-05,
      "loss": 0.3712,
      "step": 610
    },
    {
      "epoch": 0.6569536423841059,
      "grad_norm": 0.5382905602455139,
      "learning_rate": 6.871686108165429e-05,
      "loss": 0.3837,
      "step": 620
    },
    {
      "epoch": 0.6675496688741722,
      "grad_norm": 0.4381735622882843,
      "learning_rate": 6.659597030752917e-05,
      "loss": 0.3482,
      "step": 630
    },
    {
      "epoch": 0.6781456953642384,
      "grad_norm": 0.40108931064605713,
      "learning_rate": 6.447507953340404e-05,
      "loss": 0.3479,
      "step": 640
    },
    {
      "epoch": 0.6887417218543046,
      "grad_norm": 0.47026604413986206,
      "learning_rate": 6.23541887592789e-05,
      "loss": 0.3526,
      "step": 650
    },
    {
      "epoch": 0.6993377483443709,
      "grad_norm": 0.5176353454589844,
      "learning_rate": 6.023329798515377e-05,
      "loss": 0.3686,
      "step": 660
    },
    {
      "epoch": 0.7099337748344371,
      "grad_norm": 0.429470419883728,
      "learning_rate": 5.811240721102863e-05,
      "loss": 0.3376,
      "step": 670
    },
    {
      "epoch": 0.7205298013245033,
      "grad_norm": 0.41110357642173767,
      "learning_rate": 5.59915164369035e-05,
      "loss": 0.3523,
      "step": 680
    },
    {
      "epoch": 0.7311258278145696,
      "grad_norm": 0.5118547081947327,
      "learning_rate": 5.387062566277837e-05,
      "loss": 0.3553,
      "step": 690
    },
    {
      "epoch": 0.7417218543046358,
      "grad_norm": 0.3958134949207306,
      "learning_rate": 5.1749734888653236e-05,
      "loss": 0.3467,
      "step": 700
    },
    {
      "epoch": 0.752317880794702,
      "grad_norm": 0.3998582363128662,
      "learning_rate": 4.9628844114528106e-05,
      "loss": 0.3413,
      "step": 710
    },
    {
      "epoch": 0.7629139072847683,
      "grad_norm": 0.41165274381637573,
      "learning_rate": 4.750795334040297e-05,
      "loss": 0.3599,
      "step": 720
    },
    {
      "epoch": 0.7735099337748345,
      "grad_norm": 0.5307395458221436,
      "learning_rate": 4.538706256627784e-05,
      "loss": 0.3528,
      "step": 730
    },
    {
      "epoch": 0.7841059602649006,
      "grad_norm": 0.42496147751808167,
      "learning_rate": 4.32661717921527e-05,
      "loss": 0.3538,
      "step": 740
    },
    {
      "epoch": 0.7947019867549668,
      "grad_norm": 0.43405795097351074,
      "learning_rate": 4.1145281018027574e-05,
      "loss": 0.3623,
      "step": 750
    },
    {
      "epoch": 0.8052980132450331,
      "grad_norm": 0.45252785086631775,
      "learning_rate": 3.9024390243902444e-05,
      "loss": 0.3424,
      "step": 760
    },
    {
      "epoch": 0.8158940397350993,
      "grad_norm": 0.4274636209011078,
      "learning_rate": 3.690349946977731e-05,
      "loss": 0.3582,
      "step": 770
    },
    {
      "epoch": 0.8264900662251655,
      "grad_norm": 0.44209176301956177,
      "learning_rate": 3.478260869565218e-05,
      "loss": 0.3497,
      "step": 780
    },
    {
      "epoch": 0.8370860927152318,
      "grad_norm": 0.35905706882476807,
      "learning_rate": 3.266171792152704e-05,
      "loss": 0.3288,
      "step": 790
    },
    {
      "epoch": 0.847682119205298,
      "grad_norm": 0.39790064096450806,
      "learning_rate": 3.054082714740191e-05,
      "loss": 0.3483,
      "step": 800
    },
    {
      "epoch": 0.8582781456953642,
      "grad_norm": 0.4918704032897949,
      "learning_rate": 2.8419936373276778e-05,
      "loss": 0.3373,
      "step": 810
    },
    {
      "epoch": 0.8688741721854305,
      "grad_norm": 0.43856358528137207,
      "learning_rate": 2.6299045599151645e-05,
      "loss": 0.3479,
      "step": 820
    },
    {
      "epoch": 0.8794701986754967,
      "grad_norm": 0.4389280080795288,
      "learning_rate": 2.4178154825026512e-05,
      "loss": 0.3366,
      "step": 830
    },
    {
      "epoch": 0.8900662251655629,
      "grad_norm": 0.5281457901000977,
      "learning_rate": 2.205726405090138e-05,
      "loss": 0.3501,
      "step": 840
    },
    {
      "epoch": 0.9006622516556292,
      "grad_norm": 0.42170238494873047,
      "learning_rate": 1.9936373276776246e-05,
      "loss": 0.3577,
      "step": 850
    },
    {
      "epoch": 0.9112582781456954,
      "grad_norm": 0.47555291652679443,
      "learning_rate": 1.7815482502651116e-05,
      "loss": 0.3744,
      "step": 860
    },
    {
      "epoch": 0.9218543046357616,
      "grad_norm": 0.5264809727668762,
      "learning_rate": 1.5694591728525983e-05,
      "loss": 0.3603,
      "step": 870
    },
    {
      "epoch": 0.9324503311258279,
      "grad_norm": 0.44922444224357605,
      "learning_rate": 1.357370095440085e-05,
      "loss": 0.3441,
      "step": 880
    },
    {
      "epoch": 0.9430463576158941,
      "grad_norm": 0.4468843638896942,
      "learning_rate": 1.1452810180275717e-05,
      "loss": 0.3723,
      "step": 890
    },
    {
      "epoch": 0.9536423841059603,
      "grad_norm": 0.4844468832015991,
      "learning_rate": 9.331919406150584e-06,
      "loss": 0.3556,
      "step": 900
    },
    {
      "epoch": 0.9642384105960264,
      "grad_norm": 0.48254871368408203,
      "learning_rate": 7.211028632025451e-06,
      "loss": 0.3592,
      "step": 910
    },
    {
      "epoch": 0.9748344370860927,
      "grad_norm": 0.47992032766342163,
      "learning_rate": 5.090137857900318e-06,
      "loss": 0.3316,
      "step": 920
    },
    {
      "epoch": 0.9854304635761589,
      "grad_norm": 0.4380919635295868,
      "learning_rate": 2.9692470837751856e-06,
      "loss": 0.366,
      "step": 930
    },
    {
      "epoch": 0.9960264900662251,
      "grad_norm": 0.4673927128314972,
      "learning_rate": 8.483563096500531e-07,
      "loss": 0.3548,
      "step": 940
    },
    {
      "epoch": 1.0074172185430463,
      "grad_norm": 0.5258150100708008,
      "learning_rate": 9.936373276776246e-05,
      "loss": 0.3486,
      "step": 950
    },
    {
      "epoch": 1.0180132450331125,
      "grad_norm": 0.38547301292419434,
      "learning_rate": 9.83032873806999e-05,
      "loss": 0.3473,
      "step": 960
    },
    {
      "epoch": 1.0286092715231787,
      "grad_norm": 0.5153177380561829,
      "learning_rate": 9.724284199363733e-05,
      "loss": 0.358,
      "step": 970
    },
    {
      "epoch": 1.0392052980132451,
      "grad_norm": 0.5667901039123535,
      "learning_rate": 9.618239660657477e-05,
      "loss": 0.3478,
      "step": 980
    },
    {
      "epoch": 1.0498013245033113,
      "grad_norm": 0.4813578128814697,
      "learning_rate": 9.51219512195122e-05,
      "loss": 0.34,
      "step": 990
    },
    {
      "epoch": 1.0603973509933775,
      "grad_norm": 0.42760518193244934,
      "learning_rate": 9.406150583244964e-05,
      "loss": 0.3354,
      "step": 1000
    },
    {
      "epoch": 1.0709933774834437,
      "grad_norm": 0.4761951267719269,
      "learning_rate": 9.300106044538707e-05,
      "loss": 0.3395,
      "step": 1010
    },
    {
      "epoch": 1.0815894039735099,
      "grad_norm": 0.457400381565094,
      "learning_rate": 9.194061505832449e-05,
      "loss": 0.3337,
      "step": 1020
    },
    {
      "epoch": 1.092185430463576,
      "grad_norm": 0.4791916310787201,
      "learning_rate": 9.088016967126194e-05,
      "loss": 0.3393,
      "step": 1030
    },
    {
      "epoch": 1.1027814569536423,
      "grad_norm": 0.4210119843482971,
      "learning_rate": 8.981972428419936e-05,
      "loss": 0.3523,
      "step": 1040
    },
    {
      "epoch": 1.1133774834437087,
      "grad_norm": 0.4722071588039398,
      "learning_rate": 8.87592788971368e-05,
      "loss": 0.3377,
      "step": 1050
    },
    {
      "epoch": 1.1239735099337749,
      "grad_norm": 0.48381221294403076,
      "learning_rate": 8.769883351007425e-05,
      "loss": 0.3419,
      "step": 1060
    },
    {
      "epoch": 1.134569536423841,
      "grad_norm": 0.5573957562446594,
      "learning_rate": 8.663838812301167e-05,
      "loss": 0.3291,
      "step": 1070
    },
    {
      "epoch": 1.1451655629139073,
      "grad_norm": 0.5575964450836182,
      "learning_rate": 8.55779427359491e-05,
      "loss": 0.333,
      "step": 1080
    },
    {
      "epoch": 1.1557615894039734,
      "grad_norm": 0.5069671869277954,
      "learning_rate": 8.451749734888653e-05,
      "loss": 0.3443,
      "step": 1090
    },
    {
      "epoch": 1.1663576158940399,
      "grad_norm": 0.4527057111263275,
      "learning_rate": 8.345705196182397e-05,
      "loss": 0.3445,
      "step": 1100
    },
    {
      "epoch": 1.176953642384106,
      "grad_norm": 0.558662474155426,
      "learning_rate": 8.239660657476141e-05,
      "loss": 0.3375,
      "step": 1110
    },
    {
      "epoch": 1.1875496688741722,
      "grad_norm": 0.6032255291938782,
      "learning_rate": 8.133616118769883e-05,
      "loss": 0.3552,
      "step": 1120
    },
    {
      "epoch": 1.1981456953642384,
      "grad_norm": 0.4940957725048065,
      "learning_rate": 8.027571580063628e-05,
      "loss": 0.3491,
      "step": 1130
    },
    {
      "epoch": 1.2087417218543046,
      "grad_norm": 0.43484753370285034,
      "learning_rate": 7.92152704135737e-05,
      "loss": 0.3556,
      "step": 1140
    },
    {
      "epoch": 1.2193377483443708,
      "grad_norm": 0.4927199184894562,
      "learning_rate": 7.815482502651114e-05,
      "loss": 0.3373,
      "step": 1150
    },
    {
      "epoch": 1.229933774834437,
      "grad_norm": 0.506223201751709,
      "learning_rate": 7.709437963944857e-05,
      "loss": 0.3331,
      "step": 1160
    },
    {
      "epoch": 1.2405298013245032,
      "grad_norm": 0.4662991464138031,
      "learning_rate": 7.6033934252386e-05,
      "loss": 0.3342,
      "step": 1170
    },
    {
      "epoch": 1.2511258278145696,
      "grad_norm": 0.5710067749023438,
      "learning_rate": 7.497348886532344e-05,
      "loss": 0.3475,
      "step": 1180
    },
    {
      "epoch": 1.2617218543046358,
      "grad_norm": 0.5358666181564331,
      "learning_rate": 7.391304347826086e-05,
      "loss": 0.3397,
      "step": 1190
    },
    {
      "epoch": 1.272317880794702,
      "grad_norm": 0.5310144424438477,
      "learning_rate": 7.285259809119831e-05,
      "loss": 0.3576,
      "step": 1200
    },
    {
      "epoch": 1.2829139072847682,
      "grad_norm": 0.48928096890449524,
      "learning_rate": 7.179215270413573e-05,
      "loss": 0.3308,
      "step": 1210
    },
    {
      "epoch": 1.2935099337748344,
      "grad_norm": 0.51631098985672,
      "learning_rate": 7.073170731707317e-05,
      "loss": 0.3463,
      "step": 1220
    },
    {
      "epoch": 1.3041059602649008,
      "grad_norm": 0.4729517698287964,
      "learning_rate": 6.967126193001062e-05,
      "loss": 0.3556,
      "step": 1230
    },
    {
      "epoch": 1.314701986754967,
      "grad_norm": 0.5762951374053955,
      "learning_rate": 6.861081654294804e-05,
      "loss": 0.3181,
      "step": 1240
    },
    {
      "epoch": 1.3252980132450332,
      "grad_norm": 0.5877885222434998,
      "learning_rate": 6.755037115588547e-05,
      "loss": 0.3265,
      "step": 1250
    },
    {
      "epoch": 1.3358940397350993,
      "grad_norm": 0.5723351836204529,
      "learning_rate": 6.648992576882291e-05,
      "loss": 0.342,
      "step": 1260
    },
    {
      "epoch": 1.3464900662251655,
      "grad_norm": 0.6107922792434692,
      "learning_rate": 6.542948038176034e-05,
      "loss": 0.3726,
      "step": 1270
    },
    {
      "epoch": 1.3570860927152317,
      "grad_norm": 0.5036354064941406,
      "learning_rate": 6.436903499469778e-05,
      "loss": 0.3373,
      "step": 1280
    },
    {
      "epoch": 1.367682119205298,
      "grad_norm": 0.5534846782684326,
      "learning_rate": 6.33085896076352e-05,
      "loss": 0.3498,
      "step": 1290
    },
    {
      "epoch": 1.378278145695364,
      "grad_norm": 0.531029462814331,
      "learning_rate": 6.224814422057265e-05,
      "loss": 0.3527,
      "step": 1300
    },
    {
      "epoch": 1.3888741721854305,
      "grad_norm": 0.5867980122566223,
      "learning_rate": 6.118769883351007e-05,
      "loss": 0.3583,
      "step": 1310
    },
    {
      "epoch": 1.3994701986754967,
      "grad_norm": 0.5855569839477539,
      "learning_rate": 6.0127253446447506e-05,
      "loss": 0.3773,
      "step": 1320
    },
    {
      "epoch": 1.410066225165563,
      "grad_norm": 0.48464712500572205,
      "learning_rate": 5.906680805938495e-05,
      "loss": 0.3387,
      "step": 1330
    },
    {
      "epoch": 1.420662251655629,
      "grad_norm": 0.5700204372406006,
      "learning_rate": 5.8006362672322377e-05,
      "loss": 0.3407,
      "step": 1340
    },
    {
      "epoch": 1.4312582781456953,
      "grad_norm": 0.4827337861061096,
      "learning_rate": 5.694591728525981e-05,
      "loss": 0.3368,
      "step": 1350
    },
    {
      "epoch": 1.4418543046357617,
      "grad_norm": 0.49599939584732056,
      "learning_rate": 5.5885471898197254e-05,
      "loss": 0.3198,
      "step": 1360
    },
    {
      "epoch": 1.4524503311258279,
      "grad_norm": 0.6056751608848572,
      "learning_rate": 5.482502651113468e-05,
      "loss": 0.3489,
      "step": 1370
    },
    {
      "epoch": 1.463046357615894,
      "grad_norm": 0.5254007577896118,
      "learning_rate": 5.376458112407211e-05,
      "loss": 0.3316,
      "step": 1380
    },
    {
      "epoch": 1.4736423841059603,
      "grad_norm": 0.6283527612686157,
      "learning_rate": 5.270413573700954e-05,
      "loss": 0.3364,
      "step": 1390
    },
    {
      "epoch": 1.4842384105960265,
      "grad_norm": 0.5242188572883606,
      "learning_rate": 5.164369034994698e-05,
      "loss": 0.3554,
      "step": 1400
    },
    {
      "epoch": 1.4948344370860926,
      "grad_norm": 0.49200958013534546,
      "learning_rate": 5.0583244962884416e-05,
      "loss": 0.3484,
      "step": 1410
    },
    {
      "epoch": 1.5054304635761588,
      "grad_norm": 0.5610643029212952,
      "learning_rate": 4.952279957582185e-05,
      "loss": 0.3311,
      "step": 1420
    },
    {
      "epoch": 1.516026490066225,
      "grad_norm": 0.4788800776004791,
      "learning_rate": 4.846235418875928e-05,
      "loss": 0.326,
      "step": 1430
    },
    {
      "epoch": 1.5266225165562914,
      "grad_norm": 0.4794853627681732,
      "learning_rate": 4.7401908801696714e-05,
      "loss": 0.3366,
      "step": 1440
    },
    {
      "epoch": 1.5372185430463576,
      "grad_norm": 0.5807623863220215,
      "learning_rate": 4.634146341463415e-05,
      "loss": 0.3282,
      "step": 1450
    },
    {
      "epoch": 1.5478145695364238,
      "grad_norm": 0.5523927807807922,
      "learning_rate": 4.528101802757158e-05,
      "loss": 0.3486,
      "step": 1460
    },
    {
      "epoch": 1.55841059602649,
      "grad_norm": 0.459764689207077,
      "learning_rate": 4.422057264050902e-05,
      "loss": 0.323,
      "step": 1470
    },
    {
      "epoch": 1.5690066225165564,
      "grad_norm": 0.5087031126022339,
      "learning_rate": 4.316012725344645e-05,
      "loss": 0.3177,
      "step": 1480
    },
    {
      "epoch": 1.5796026490066226,
      "grad_norm": 0.5916008949279785,
      "learning_rate": 4.209968186638388e-05,
      "loss": 0.3336,
      "step": 1490
    },
    {
      "epoch": 1.5901986754966888,
      "grad_norm": 0.5422638654708862,
      "learning_rate": 4.103923647932132e-05,
      "loss": 0.3229,
      "step": 1500
    },
    {
      "epoch": 1.600794701986755,
      "grad_norm": 0.536346435546875,
      "learning_rate": 3.997879109225875e-05,
      "loss": 0.3531,
      "step": 1510
    },
    {
      "epoch": 1.6113907284768212,
      "grad_norm": 0.53546142578125,
      "learning_rate": 3.891834570519618e-05,
      "loss": 0.3263,
      "step": 1520
    },
    {
      "epoch": 1.6219867549668874,
      "grad_norm": 0.540348470211029,
      "learning_rate": 3.785790031813362e-05,
      "loss": 0.3261,
      "step": 1530
    },
    {
      "epoch": 1.6325827814569536,
      "grad_norm": 0.5304887294769287,
      "learning_rate": 3.679745493107105e-05,
      "loss": 0.3404,
      "step": 1540
    },
    {
      "epoch": 1.6431788079470198,
      "grad_norm": 0.5164585709571838,
      "learning_rate": 3.573700954400849e-05,
      "loss": 0.3533,
      "step": 1550
    },
    {
      "epoch": 1.653774834437086,
      "grad_norm": 0.48783767223358154,
      "learning_rate": 3.4676564156945916e-05,
      "loss": 0.3337,
      "step": 1560
    },
    {
      "epoch": 1.6643708609271524,
      "grad_norm": 0.4905361235141754,
      "learning_rate": 3.361611876988335e-05,
      "loss": 0.3296,
      "step": 1570
    },
    {
      "epoch": 1.6749668874172186,
      "grad_norm": 0.608383059501648,
      "learning_rate": 3.2555673382820786e-05,
      "loss": 0.3405,
      "step": 1580
    },
    {
      "epoch": 1.6855629139072847,
      "grad_norm": 0.5500990152359009,
      "learning_rate": 3.149522799575822e-05,
      "loss": 0.3137,
      "step": 1590
    },
    {
      "epoch": 1.6961589403973512,
      "grad_norm": 0.554129958152771,
      "learning_rate": 3.0434782608695656e-05,
      "loss": 0.337,
      "step": 1600
    },
    {
      "epoch": 1.7067549668874173,
      "grad_norm": 0.5297702550888062,
      "learning_rate": 2.9374337221633085e-05,
      "loss": 0.3223,
      "step": 1610
    },
    {
      "epoch": 1.7173509933774835,
      "grad_norm": 0.5801765322685242,
      "learning_rate": 2.8313891834570523e-05,
      "loss": 0.334,
      "step": 1620
    },
    {
      "epoch": 1.7279470198675497,
      "grad_norm": 0.5250349044799805,
      "learning_rate": 2.725344644750795e-05,
      "loss": 0.354,
      "step": 1630
    },
    {
      "epoch": 1.738543046357616,
      "grad_norm": 0.6329443454742432,
      "learning_rate": 2.6193001060445387e-05,
      "loss": 0.3377,
      "step": 1640
    },
    {
      "epoch": 1.749139072847682,
      "grad_norm": 0.5479766130447388,
      "learning_rate": 2.5132555673382825e-05,
      "loss": 0.3413,
      "step": 1650
    },
    {
      "epoch": 1.7597350993377483,
      "grad_norm": 0.5104653239250183,
      "learning_rate": 2.4072110286320257e-05,
      "loss": 0.3274,
      "step": 1660
    },
    {
      "epoch": 1.7703311258278145,
      "grad_norm": 0.5888098478317261,
      "learning_rate": 2.301166489925769e-05,
      "loss": 0.3533,
      "step": 1670
    },
    {
      "epoch": 1.7809271523178807,
      "grad_norm": 0.49184396862983704,
      "learning_rate": 2.1951219512195124e-05,
      "loss": 0.3274,
      "step": 1680
    },
    {
      "epoch": 1.7915231788079469,
      "grad_norm": 0.6710692048072815,
      "learning_rate": 2.0890774125132556e-05,
      "loss": 0.3351,
      "step": 1690
    },
    {
      "epoch": 1.8021192052980133,
      "grad_norm": 0.5405354499816895,
      "learning_rate": 1.983032873806999e-05,
      "loss": 0.3264,
      "step": 1700
    },
    {
      "epoch": 1.8127152317880795,
      "grad_norm": 0.5592615604400635,
      "learning_rate": 1.8769883351007426e-05,
      "loss": 0.3485,
      "step": 1710
    },
    {
      "epoch": 1.8233112582781457,
      "grad_norm": 0.5901895761489868,
      "learning_rate": 1.7709437963944858e-05,
      "loss": 0.3295,
      "step": 1720
    },
    {
      "epoch": 1.833907284768212,
      "grad_norm": 0.5219140648841858,
      "learning_rate": 1.6648992576882293e-05,
      "loss": 0.3558,
      "step": 1730
    },
    {
      "epoch": 1.8445033112582783,
      "grad_norm": 0.5032379031181335,
      "learning_rate": 1.5588547189819724e-05,
      "loss": 0.3232,
      "step": 1740
    },
    {
      "epoch": 1.8550993377483445,
      "grad_norm": 0.5819023251533508,
      "learning_rate": 1.4528101802757158e-05,
      "loss": 0.342,
      "step": 1750
    },
    {
      "epoch": 1.8656953642384106,
      "grad_norm": 0.6864577531814575,
      "learning_rate": 1.3467656415694593e-05,
      "loss": 0.3368,
      "step": 1760
    },
    {
      "epoch": 1.8762913907284768,
      "grad_norm": 0.5718769431114197,
      "learning_rate": 1.2407211028632027e-05,
      "loss": 0.32,
      "step": 1770
    },
    {
      "epoch": 1.886887417218543,
      "grad_norm": 0.561771035194397,
      "learning_rate": 1.134676564156946e-05,
      "loss": 0.3398,
      "step": 1780
    },
    {
      "epoch": 1.8974834437086092,
      "grad_norm": 0.6299818158149719,
      "learning_rate": 1.0286320254506893e-05,
      "loss": 0.3323,
      "step": 1790
    },
    {
      "epoch": 1.9080794701986754,
      "grad_norm": 0.6158187389373779,
      "learning_rate": 9.225874867444327e-06,
      "loss": 0.3418,
      "step": 1800
    },
    {
      "epoch": 1.9186754966887416,
      "grad_norm": 0.6426305174827576,
      "learning_rate": 8.16542948038176e-06,
      "loss": 0.3249,
      "step": 1810
    },
    {
      "epoch": 1.9292715231788078,
      "grad_norm": 0.537946343421936,
      "learning_rate": 7.1049840933191946e-06,
      "loss": 0.3315,
      "step": 1820
    },
    {
      "epoch": 1.9398675496688742,
      "grad_norm": 0.6581951975822449,
      "learning_rate": 6.044538706256628e-06,
      "loss": 0.3229,
      "step": 1830
    },
    {
      "epoch": 1.9504635761589404,
      "grad_norm": 0.6890716552734375,
      "learning_rate": 4.9840933191940615e-06,
      "loss": 0.3292,
      "step": 1840
    },
    {
      "epoch": 1.9610596026490066,
      "grad_norm": 0.5330506563186646,
      "learning_rate": 3.923647932131496e-06,
      "loss": 0.3221,
      "step": 1850
    },
    {
      "epoch": 1.971655629139073,
      "grad_norm": 0.6262726783752441,
      "learning_rate": 2.863202545068929e-06,
      "loss": 0.3521,
      "step": 1860
    },
    {
      "epoch": 1.9822516556291392,
      "grad_norm": 0.5861164331436157,
      "learning_rate": 1.8027571580063629e-06,
      "loss": 0.2931,
      "step": 1870
    },
    {
      "epoch": 1.9928476821192054,
      "grad_norm": 0.5821825861930847,
      "learning_rate": 7.423117709437964e-07,
      "loss": 0.3412,
      "step": 1880
    }
  ],
  "logging_steps": 10,
  "max_steps": 1886,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.280634847199232e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
